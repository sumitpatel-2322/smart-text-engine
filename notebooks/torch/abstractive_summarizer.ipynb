{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d48f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5548b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d33100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\LENOVO\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME=\"facebook/bart-large-cnn\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84d0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(\n",
    "    text: str,\n",
    "    max_input_length=1024,\n",
    "    max_summary_length=150,\n",
    "    min_summary_length=40\n",
    ")->str:\n",
    "    inputs=tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_input_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs={k: v.to(device) for k,v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        summary_ids=model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_summary_length,\n",
    "            min_length=min_summary_length,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    summary=tokenizer.decode(\n",
    "        summary_ids[0],\n",
    "        skip_special_tokens=True\n",
    "        )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15403167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A very well made movie. Loved every minute of it. The acting was great, the direction was sharp, and the story kept me hooked. There were a few slow moments, but overall it was aantastic experience that I would happily watch again.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "A very well made movie. Loved every minute of it.\n",
    "It was a roller coaster ride. The acting was great,\n",
    "the direction was sharp, and the story kept me hooked.\n",
    "There were a few slow moments, but overall it was a\n",
    "fantastic experience that I would happily watch again.\n",
    "\"\"\"\n",
    "\n",
    "print(summarize_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b78825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(\n",
    "    text: str,\n",
    "    tokenizer,\n",
    "    max_tokens: int = 1024,\n",
    "    overlap: int = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits text into token-based chunks with overlap.\n",
    "    Overlap helps preserve context between chunks.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "        start = end - overlap  # overlap for context\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926975f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunk(\n",
    "    text: str,\n",
    "    max_input_length: int = 1024,\n",
    "    max_summary_length: int = 150,\n",
    "    min_summary_length: int = 40\n",
    ") -> str:\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_input_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_summary_length,\n",
    "            min_length=min_summary_length,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e07de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_long_text(\n",
    "    text: str,\n",
    "    max_tokens: int = 1024,\n",
    "    overlap: int = 50,\n",
    "    final_summary: bool = True\n",
    ") -> str:\n",
    "    chunks = chunk_text(\n",
    "        text,\n",
    "        tokenizer=tokenizer,\n",
    "        max_tokens=max_tokens,\n",
    "        overlap=overlap\n",
    "    )\n",
    "\n",
    "    chunk_summaries = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        summary = summarize_chunk(chunk)\n",
    "        chunk_summaries.append(summary)\n",
    "\n",
    "    merged_summary = \" \".join(chunk_summaries)\n",
    "\n",
    "    # Optional second-pass summarization\n",
    "    if final_summary and len(chunks) > 1:\n",
    "        merged_summary = summarize_chunk(\n",
    "            merged_summary,\n",
    "            max_summary_length=180,\n",
    "            min_summary_length=60\n",
    "        )\n",
    "\n",
    "    return merged_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d13377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story itself starts off strong, introducing the main characters and their motivations in a way that feels natural rather than forced. The lead actor delivers a convincing performance, showing a good range of emotions and making the character feel believable. The themes explored in the movie are handled with a decent level of maturity, even if they aren’t particularly groundbreaking.\n"
     ]
    }
   ],
   "source": [
    "long_text = \"\"\"\n",
    "I went into this movie with fairly high expectations, mostly because of the cast and the amount of praise it had been receiving online. From the very first scene, it was clear that a lot of effort had gone into the visual presentation. The cinematography was impressive, with well-composed shots and a color palette that set the mood effectively. The background score also complemented the scenes nicely, never overpowering the dialogue but still adding emotional weight where needed.\n",
    "\n",
    "The story itself starts off strong, introducing the main characters and their motivations in a way that feels natural rather than forced. The first act does a good job of building intrigue and making you care about what happens next. The lead actor delivers a convincing performance, showing a good range of emotions and making the character feel believable. Supporting characters also have their moments, especially one standout performance that adds depth to what could have been a very generic role.\n",
    "\n",
    "However, as the movie progresses into the second act, the pacing begins to slow down noticeably. Certain scenes feel unnecessarily stretched, and there are moments where the narrative seems to lose focus. While some of these slower moments help in character development, others feel repetitive and could have been trimmed without affecting the overall story. This is where the movie tests the viewer’s patience, especially for those who prefer tighter storytelling.\n",
    "\n",
    "The screenplay has its strengths, particularly in its dialogue. Many conversations feel authentic and grounded, avoiding overly dramatic or unrealistic exchanges. That said, there are also a few lines that feel cliché and predictable, which slightly detracts from the otherwise solid writing. The themes explored in the movie—such as ambition, regret, and personal growth—are handled with a decent level of maturity, even if they aren’t particularly groundbreaking.\n",
    "\n",
    "One of the highlights of the film is its direction. The director clearly has a strong vision and isn’t afraid to let scenes breathe. There are several moments of silence that speak louder than words, allowing the audience to absorb the emotions of the characters. The use of close-up shots during key emotional moments is especially effective and adds intimacy to the storytelling.\n",
    "\n",
    "As the film moves toward its climax, it regains some of the momentum it lost earlier. The conflicts introduced in the first half finally come to a head, and the stakes feel real. The emotional payoff, while not perfect, is satisfying enough to justify the buildup. The final act ties up most loose ends, though a few questions are left unanswered, which some viewers may find frustrating.\n",
    "\n",
    "The ending itself is bittersweet and stays true to the tone of the movie. It avoids taking the easy route and instead opts for a conclusion that feels realistic, even if it’s not entirely uplifting. This choice may divide audiences, but it fits the story the film was trying to tell.\n",
    "\n",
    "Overall, this movie is a well-made piece of cinema with strong performances, good direction, and high production values. While it does suffer from pacing issues and a few predictable moments, it still manages to leave a lasting impression. It’s not a perfect film, but it’s one that stays with you after the credits roll. I wouldn’t call it a masterpiece, but it’s definitely worth watching, especially if you appreciate character-driven stories and thoughtful filmmaking.\n",
    "\"\"\"\n",
    "\n",
    "print(summarize_long_text(long_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408bb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59524b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
